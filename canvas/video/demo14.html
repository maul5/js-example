<!DOCTYPE html> 
<html>
<title>Video/Canvas Demo 14: Worker fork, Filters, Transferable, Animation</title> 
<script> 
//import * as filter from "./filter.js";
document.addEventListener('DOMContentLoaded', function(){
	// video source
	var video = document.getElementById('v');

	// physical canvas for rendering
	var canvas = document.getElementById('c');
	var context = canvas.getContext('2d', {desynchronized: true});
	
	// virtual canvas for processing
	var backcanvas = document.createElement('canvas');
	var backcontext = backcanvas.getContext('2d', {desynchronized: true});
 
	// main event handler
	video.addEventListener('play', () => {
   		function step() {
			if (video.paused || video.ended) return false;
			backcanvas.width = video.clientWidth;
			backcanvas.height = video.clientHeight;
			backcontext.drawImage(v, 0,0, video.clientWidth, video.clientHeight)
			let img = backcontext.getImageData(0,0, video.clientWidth, video.clientHeight);
			worker1.postMessage({msg: 'work', img: img}, [img.data.buffer]);
			requestAnimationFrame(step)
		}
  		requestAnimationFrame(step);
	})
//},false);

	// code for set of filter functions
	const filter = document.querySelector('#Filter').textContent;

	// --- the first worker : WorkerOne
	var blobOne = new Blob(["onmessage = " + workerOne + "\n"], { type: 'text/javascript' });
	const urlOne = URL.createObjectURL(blobOne);
	const worker1 = new Worker(urlOne);

	worker1.onerror = function(e) {
		document.getElementById('e').textContent = 
			['ERROR>' + e.filename + e.lineno + ' >> ' + e.message + '\n'];
	}
	worker1.onmessage = function(e) {
		switch (e.data.msg) {
			case 'start':
				console.log('worker1:', e.data.msg, 'ready')	
				break;
			case 'work':
				img = e.data.img;
				worker2.postMessage({msg: e.data.msg, img: img}, [img.data.buffer]);
				break;
			case 'done':
				img = e.data.img;
				canvas.width = video.clientWidth;
				canvas.height = video.clientHeight;
				context.putImageData(img,0,0)
				break;
			case 'end':
				worker1.terminate(); 
				break;
		}
	}
	worker1.postMessage({msg: 'start'});

	function workerOne(e) {
		switch (e.data.msg) {
			case 'start':
				postMessage({msg: e.data.msg});
				//postMessage(1/x);
				break;
			case 'work':
				img = e.data.img;
				postMessage({msg: e.data.msg, img: img}, [img.data.buffer]);
				break;
			case 'done':
				img = e.data.img;
				postMessage({msg: e.data.msg, img: img}, [img.data.buffer]);
				break;
			case 'end': 
				postMessage({msg: e.data.msg});
				close();
				break;
		}
	}

	// --- another second worker : WorkerTwo
	var blobTwo = new Blob(["onmessage = " + workerTwo + "\n" + filter + "\n"], { type: 'text/javascript' });
	const urlTwo = URL.createObjectURL(blobTwo);
	const worker2 = new Worker(urlTwo);

	worker2.onmessage = function(e) {
		switch (e.data.msg) {
			case 'start':
				console.log('worker2:', e.data.msg, 'ready')
				break;
			case 'work':
				break;
			case 'done':
				img = e.data.img;
				worker1.postMessage({msg: e.data.msg, img: img}, [img.data.buffer]);
				break;
			case 'end': 
				console.log('worker2:', e.data.msg, 'close')
				worker2.terminate();
				break;
		}
	}
	worker2.postMessage({msg: 'start'});


	function workerTwo(e) {
		switch (e.data.msg) {
			case 'start':
				postMessage({msg: e.data.msg});
				break;
			case 'work':
				img = e.data.img;
				brightness(img.data, 6);
				chromakey(img.data);
				sepia(img.data);
				invert(img.data);
				grayscale(img.data);
				postMessage({msg: 'done', img: img}, [img.data.buffer]);
				break;
			case 'done':
				break;
			case 'end': 
				postMessage({msg: e.data.msg});
				close();
				break;
		}
	}	
},false);
</script>

<script type="text/javascript" id="Filter">
	// CAUTION: image is not shared area, use image.data
	function chromakey(data) {
		for (let i = 0; i < data.length; i+=4) {
			let r = data[i+0];
			let g = data[i+1];
			let b = data[i+2];
			if (g > 100 && r > 100 && b < 50)
				data[i+ 3] = 0;
		}
		return data;
	}

	function invert(data) {
		for (let i = 0; i < data.length/2; i+=4) {
			data[i] = 255 - data[i];		// R
			data[i+1] = 255 - data[i+1]; 	// G
			data[i+2] = 255 - data[i+2]; 	// B
			data[i+3] = 255;			// alpha
		}
		return data;
	}

	function brightness(data, value) {
		for(var i =0; i< data.length; i+=4){
			data[i] += value/3;
			data[i+1] += value/3;
			data[i+2] += value/3;
		}
		return data;
	}

	function grayscale(data) {
		for(var i =0; i< data.length; i+=4){
			let r = data[i];
			let g = data[i+1];
			let b = data[i+2];

			var v = 0.2126*r + 0.7152*g + 0.0722*b;  // complemented value
			data[i] = data[i+1] = data[i+2] = v      // same rgb values
		}
		return data;
	}

	// old style image
	function sepia(data) {
		for (let i = 0; i < data.length; i+=4) {
			let r = data[i+0];
			let g = data[i+1];
			let b = data[i+2];
			
			data[i] = r*0.3588 + g*0.7044 + b*0.1368;
			data[i+1] = r*0.2990 + g*0.5870 + b+0.1140;
			data[i+2] = r*0.2392 + g*0.4696 + b*0.0912;
		}
		return data;
	}
</script>


<style> 
#c {
	position: absolute;
	top: 50%;
	left: 50%;
	margin: -180px 0 0 20px;
}
 
#v {
	position: absolute;
	top: 50%;
	left: 50%;
	margin: -180px 0 0 -500px;
}

#b {
	position: absolute;
	top: 110%;
	left: 20%;
	margin: -180px 0 0 20px;
}

#s {
	position: absolute;
	top: 110%;
	left: 50%;
	margin: -180px 0 0 20px;
}
</style> 

</body>
<center>
<h2>Video/Canvas Demo 14: Worker fork, Filters, Transferable, Animation</h2>
<h3>Main => Worker1 => Worker2 (filter) => Worker1 (draw)</h3>
</center>
<video id="v" class=display-none controls autoplay loop> 
	<source src=video.webm type=video/webm> 
	<source src=video.ogg type=video/ogg> 
	<source src=video.mp4 type=video/mp4> 
</video> 
<canvas id="c"></canvas> 
<input id="b" type=file accept=image/*>
<output id="e" style="color: red;"></output>
<div id="s">
<b>filter:</b> 
<select name="filter">
	<option value="invert">invert</option>
	<option value="chromekey">chromakey</option>
</select>
</div>
</body> 
</html>