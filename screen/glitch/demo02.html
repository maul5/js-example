<!DOCTYPE html>
<html lang="en">
<head>
</head>  

<style>
body {
    font-family: "Benton Sans", "Helvetica Neue", helvetica, arial, sans-serif;
    margin: 2em;
    text-align: center;
}
h2 {
    font-style: italic;
    color: blueviolet;
}
video {
    width: 70%;
    height: 70%;
}
button {
    margin: 1em;
    padding: 1em;
    border-radius: 5px;
}
</style>

<body>
<h2>World's Simplest Screenrecorder with Voice</h2>
<p id="warning">
Enable chrome://flags/#enable-experimental-web-platform-features
</p>
<video id="videoElement" autoplay muted></video>
<br />
<button id="captureBtn">Capture</button>
<button id="startBtn" disabled>Start Recording</button>
<button id="stopBtn" disabled>Stop Capture</button>
<button id="downBtn" disabled>Download</button>
<br>
<input type="checkbox" id="audioToggle" />
<label for="audioToggle">Capture Audio from Desktop</label>
<input type="checkbox" id="micAudioToggle" />
<label for="micAudioToggle">Capture Audio from Microphone</label>
<!-- <a id="download" href="#" style="display: none;">Download</a> -->
</body>

<script>
window.onload = () => {
    const warningEl = document.getElementById('warning');
    const videoElement = document.getElementById('videoElement');
    const captureBtn = document.getElementById('captureBtn');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const downBtn = document.getElementById('downBtn');
    const download = document.getElementById('download');
    const audioToggle = document.getElementById('audioToggle');
    const micAudioToggle = document.getElementById('micAudioToggle');

    if ('getDisplayMedia' in navigator.mediaDevices) warningEl.style.display = 'none';

    let blobs;
    let blob;
    let rec;
    let stream;
    let voiceStream;
    let desktopStream;

    const mergeAudioStreams = (desktopStream, voiceStream) => {
        console.log("mergeAudioStreams:")
        const context = new AudioContext();
        const destination = context.createMediaStreamDestination();
        const hasDesktop = false;
        const hasVoice = false;

        if (desktopStream && desktopStream.getAudioTracks().length > 0) {
            // If you don't want to share Audio from the desktop it should still work with just the voice.
            const source1 = context.createMediaStreamSource(desktopStream);
            const desktopGain = context.createGain();
            desktopGain.gain.value = 0.7;
            source1.connect(desktopGain).connect(destination);
        }

        if (voiceStream && voiceStream.getAudioTracks().length > 0) {
            const source2 = context.createMediaStreamSource(voiceStream);
            const voiceGain = context.createGain();
            voiceGain.gain.value = 0.7;
            source2.connect(voiceGain).connect(destination);
        }
            
        return (hasDesktop || hasVoice) ? destination.stream.getAudioTracks() : [];
    };

    captureBtn.onclick = async () => {
        console.log("Capture:")
        const audio = audioToggle.checked || false;
        const mic = micAudioToggle.checked || false;

        desktopStream = await navigator.mediaDevices.getDisplayMedia({ video:true, audio: audio });
        console.log('capture/desktop:', desktopStream)
        if (mic === true) {
            voiceStream = await navigator.mediaDevices.getUserMedia({ video: false, audio: mic });
            console.log('capture/voice:', voiceStream)
        }

        const tracks = [
            ...desktopStream.getVideoTracks(), 
            ...mergeAudioStreams(desktopStream, voiceStream)
        ];

        console.log('Tracks to add to stream', tracks);
        stream = new MediaStream(tracks);
        console.log('MediaStream:', stream)
        videoElement.srcObject = stream;
        videoElement.muted = true;
            
        blobs = [];

        rec = new MediaRecorder(stream, {mimeType: 'video/webm; codecs=vp8,opus'});
        rec.ondataavailable = (e) => blobs.push(e.data);
        rec.onstop = async () => {    
            downBtn.disabled = false;
        };
        startBtn.disabled = false;
        captureBtn.disabled = true;
    };

    startBtn.onclick = () => {
        downBtn.disabled = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        rec.start();
    };

    stopBtn.onclick = () => {
        downBtn.disabled = false;
        captureBtn.disabled = false;
        startBtn.disabled = true;
        stopBtn.disabled = true;

        rec.stop();

        stream.getTracks().forEach(s=>s.stop())
        videoElement.srcObject = null
        stream = null;
    };

    downBtn.onclick = () => {
        blob = new Blob(blobs, {type: 'video/webm'});
        let url = window.URL.createObjectURL(blob);
        var a = document.createElement('a');
        a.style.display = 'none';
        a.href = url;
        a.download = 'test.webm';
        document.body.appendChild(a);
        a.click();
        setTimeout(function() {
            document.body.removeChild(a);
            window.URL.revokeObjectURL(url);
        }, 100);
    };
};
</script>

</html>