<!DOCTYPE html>
<html lang="en">
<head>
</head>  

<style>
body {
    font-family: "Benton Sans", "Helvetica Neue", helvetica, arial, sans-serif;
    margin: 2em;
    text-align: center;
}
h2 {
    font-style: italic;
    color: blueviolet;
}
video {
    width: 70%;
    height: 70%;
}
button {
    margin: 1em;
    padding: 1em;
    border-radius: 5px;
    background-color: lightblue;
}
/* input {
    margin: 1em;
} */
</style>

<body>
<h2>Demo 04: World's Simplest Screenrecorder with Voice</h2>
<video id="videoElement" autoplay muted></video>
<br />
<button id="captureBtn">Capture</button>
<button id="startBtn" disabled>Start Recording</button>
<button id="stopBtn" disabled>Stop Capture</button>
<button id="downBtn" disabled>Download</button>
<br>
<input type="checkbox" id="spkAudioToggle" />
<label for="spkAudioToggle">Capture Audio from Desktop</label>
<input type="checkbox" id="micAudioToggle" />
<label for="micAudioToggle">Capture Audio from Microphone</label>
<p id="warning">
Enable <a href="chrome://flags">chrome://flags</a>/#enable-experimental-web-platform-features
</p>
Reference: <a href="https://paul.kinlan.me/screen-recorderrecording-microphone-and-the-desktop-audio-at-the-same-time/">Screen Recorder: recording microphone and the desktop audio at the same time</a>
</body>

<script>
window.onload = () => {
    const warningEl = document.getElementById('warning');
    const videoElement = document.getElementById('videoElement');
    const captureBtn = document.getElementById('captureBtn');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const downBtn = document.getElementById('downBtn');
    const download = document.getElementById('download');
    const spkAudioToggle = document.getElementById('spkAudioToggle');
    const micAudioToggle = document.getElementById('micAudioToggle');

    // if ('getDisplayMedia' in navigator.mediaDevices) warningEl.style.display = 'none';

    let blobs;
    let blob;
    let rec;
    let mergeStream;
    let voiceStream;
    let desktopStream;

    const mergeAudioStreams = (desktopStream, voiceStream) => {
        console.log("mergeAudioStreams: start")
        const context = new AudioContext();
        const destination = context.createMediaStreamDestination();
// console.log(destination.stream.getAudioTracks())

        var audioRealTrackCount = 0;

        if (desktopStream && desktopStream.getAudioTracks().length > 0) {
            printStreamTracks('desktopStream:', desktopStream)
            const source1 = context.createMediaStreamSource(desktopStream);
            const desktopGain = context.createGain();
            desktopGain.gain.value = 0.8;
            source1.connect(desktopGain).connect(destination);
            audioRealTrackCount++;
        }

        if (voiceStream && voiceStream.getAudioTracks().length > 0) {
            printStreamTracks('voiceStream:', voiceStream)
            const source2 = context.createMediaStreamSource(voiceStream);
            const voiceGain = context.createGain();
            voiceGain.gain.value = 0.8;
            source2.connect(voiceGain).connect(destination);
            audioRealTrackCount++;
        }
        
        if (audioRealTrackCount === 0 && destination.stream.getAudioTracks().length === 1) {
            console.log("remove an audio track without real data from its stream");
            destination.stream.removeTrack(destination.stream.getAudioTracks()[0]);
        }

        printStreamTracks("AudioStream:", destination.stream);
        return destination.stream.getAudioTracks();
    };

    captureBtn.onclick = async () => {
        console.log("Capture:")
        const spk = spkAudioToggle.checked;
        const mic = micAudioToggle.checked;
        console.log("check buttons:", spk, mic);

        desktopStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: spk });
        printStreamTracks('capture/desktop:', desktopStream);
        if (mic === true) {
            voiceStream = await navigator.mediaDevices.getUserMedia({ video: false, audio: mic });
            printStreamTracks('capture/voice:', voiceStream)
        }

        const tracks = [
            ...desktopStream.getVideoTracks(), 
            ...mergeAudioStreams(desktopStream, voiceStream)
        ];

        console.log('Tracks to add to stream', tracks);
        mergeStream = new MediaStream(tracks);
        printStreamTracks('mergeStream:', mergeStream)
        videoElement.srcObject = mergeStream;
        videoElement.muted = true;
            
        blobs = [];

        rec = new MediaRecorder(mergeStream, {mimeType: 'video/webm; codecs=vp8,opus'});
        rec.ondataavailable = (e) => blobs.push(e.data);
        rec.onstop = async () => {    
            downBtn.disabled = false;
        };
        startBtn.disabled = false;
        captureBtn.disabled = true;
    };

    startBtn.onclick = () => {
        downBtn.disabled = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        rec.start();
    };

    stopBtn.onclick = () => {
        downBtn.disabled = false;
        captureBtn.disabled = false;
        startBtn.disabled = true;
        stopBtn.disabled = true;

        rec.stop();

        mergeStream.getTracks().forEach(s=>s.stop())
        videoElement.srcObject = null
        stream = null;
    };

    downBtn.onclick = () => {
        blob = new Blob(blobs, {type: 'video/webm'});
        let url = window.URL.createObjectURL(blob);
        var a = document.createElement('a');
        a.style.display = 'none';
        a.href = url;
        a.download = 'test.webm';
        document.body.appendChild(a);
        a.click();
        setTimeout(function() {
            document.body.removeChild(a);
            window.URL.revokeObjectURL(url);
        }, 100);
    };

    function printStreamTracks(note, stream) {
        console.log(note);
        stream.getTracks().forEach( function(trk){console.log(trk)} );
    }
};
</script>

</html>